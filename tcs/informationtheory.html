<!DOCTYPE html>
<html>

<head>
	<!-- Style sheet for Bootstrap -->
	<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
		integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous" />

	<!-- Style sheets for "font awesome" icons -->
	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.13.0/css/all.css">
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

	<link rel="stylesheet" href="/assets/css/style.css">

	<meta name="viewport" content="width=device-width, initial-scale=1">

	<title>Information Theory - Context Switching</title>
</head>

<body>
	<div class="nav-placeholder" id="nav-placeholder"></div>
	<div class="title-section"></div>

	<div class="information">

		<div class="table-of-contents"></div>

		<div class="category-header-div">
			<p class="category-header" id="information-theory">Information Theory</p>

			<div class="section-header-div">
				<p class="section-header" id="information-theory-preliminaries">Preliminaries</p>

				<div class="subsection-header-div">
					<p class="subsection-header" id="shannon-information">Shannon Information</p>

					<p>
						Three properties were required by Shannon:
					</p>

					<ol>
						<li>\(I(p) \geq 0\), i.e. information is a real non-negative measure.</li>
						<li>\(I(p_{1},p_{2})=I(p_{1})+I(p_{2})\) for independent events.</li>
						<li>\(I(p)\) is a continous function of \(p\).</li>
					</ol>

					<p>
						The mathematical function that satisfies these requirements is:
					</p>

					<p>
						\(I(p)=k\;log(p)\)
					</p>

					<p>
						In the equation, the value of \(k\) is arbitrary, so we choose \(k=-1\) to
						make the math more convient.
					</p>

					<p>
						\(I(p)=-\log(p)=\log(\frac{1}{p})\)
					</p>

					<p>
						The base of the logarithm is representative of the units of measure for the
						given information, but can also be chosen arbitarily. However, today
						units of information are exclusively use base 2 logarithms, in units of bits.
					</p>

					<p>
						\(I(p)=-\log_{2}(p)=\log_{2}(\frac{1}{p})\) bits of information.
					</p>

				</div>

				<div class="subsection-header-div">
					<p class="subsection-header" id="entropy-and-average-code-length">Entropy and Average Code Length</p>

					<p>
						Let \(S=\left\{s_{1}, s_{2},\ldots s_{n}\right\}\) some information source with \(n\) symbols. Let
						\(P=\left\{p_{1}, p_{2}, \ldots p_{n}\right\}\) be the corresponding probability distribution.
					</p>

					<p>
						Entropy of the source is the defined as:
					</p>

					<p>
						\(H(S)=-\sum_{i=1}^{n}p_{i}\log_{2}(p_{i})\)
						<br>
						<br>
						\(=\sum_{i=1}^{n}p_{i}\log_{2}\frac{1}{p_{i}}\)
					</p>

					<p>
						Another important number is the average code length \(L_{avg}\), defined as:
					</p>

					<p>
						\(L_{avg}=\sum_{i=1}^{n}p_{i} \left(\lceil\log_{2}\frac{1}{p_{i}}\rceil+1\right)\)
					</p>

					<p>
						Where, \(c_{i}\) is some code string of the code set \(C\) and \(|\;|\) is the <a class="sliding-link"
							href="#cardinality">cardinality</a> of \(c_{i}\).
					</p>

					<p> Note, the entropy of the source is a lower bound on the average code length that can be achieved, given by
						\(H(S) \leq
						L_{avg}\). Meaning, that the source entropy can be reach the compression limit, but can
						never
						exceed it.
					</p>
				</div>

				<div class="subsection-header-div">
					<p class="subsection-header" id="kraft-inequality">Kraft Inequality</p>

					<p>
						\(K=\sum_{i=1}^{q}\frac{1}{r^{l^{i}}}\leq 1\)
					</p>

					<p>
						Where:
					<ul>
						<li>\(K\) is the Kraft sum</li>
						<li>\(q\) is the number of source symbols</li>
						<li>\(r\) is the radix of the channel alphabet</li>
						<li>\(l_{i}\) is the lengths of the coded symbols.</li>
					</ul>
					</p>

					<p>
						Note that the craft inequality must be satisfied for codes that called <a class="sliding-link"
							href="#uniquely-decodable">uniquely decodable</a>, instantaneous
						codes, or prefix-free codes.
					</p>
				</div>

				<div class="subsection-header-div">
					<p class="subsection-header" id="proof-of-achieving-entropy-bound">Proof of Achieving Entropy Bound</p>

					<p>
						We can prove the entropy bound that can be achieved using a sufficiently large extension. We can first
						define that:
					</p>

					<p>
						\(H(S)\leq L_{avg} < H(S)+1\) </p>

							<p>
								We take the extension for any code to the \(n^{th}\) term, resulting in:
							</p>

							<p>
								\(H(S^{n})\leq L_{n} < H(S^{n})+1\) </p>

									<p>
										We sequence \(n\) symbols from \(S\), taken from the extended source \(S^{n}\), which now has
										\(q^{n}\) symbols.
									</p>

									<p>
										Lastly, we divide our previous equation by \(n\), giving us:
									</p>

									<p>
										\(H(S)\leq \frac{L_{n}}{n} < H(S)+\frac{1}{n}\) </p>

											<p>
												What this shows, is that by choosing \(n\) sufficently large, the average code length can come
												arbitrarily closer to source entropy, \(H(S)\).
											</p>

											<p>
												This being said, there are practical limitations to choosing a large extension on
												our source symbols. As the extensions on our souce become larger, the returns on efficecny
												deminish and
												have a higher cost on delay, stroage, and computation.
											</p>
				</div>
			</div>

			<div class="section-header-div">
				<p class="section-header" id="hamming-distance-and-hamming-spaces">Hamming Distance and Hamming Spaces</p>
				<div class="subsection-header-div">
					<p class="subsection-header" id="hamming-distance">Hamming Distance</p>
					<p>
						Given two N-bit binary symbols, the Hamming distance between them is the number of symbols that differ.
						For example, if the symbols are \(0110\) and \(1010\) is 2.
					</p>

					<p>
						Binary numbers as points can be represented as an \(N\)-dimensional Hamming space.
					</p>

					<p>
						To continue.
					</p>
				</div>

				<div class="subsection-header-div">
					<p class="subsection-header" id="hamming-spaces">Hamming Spaces</p>
					<p>
						To continue.
					</p>
				</div>
			</div>

			<!-- <div class="section-header-div">
				<p class="section-header" id="markov-source-modeling">Markov Source Modeling</p>

				<p>
					To continue.
				</p>

			</div>

			<div class="section-header-div">
				<p class="section-header" id="compression-algorithms">Compression Algorithms</p>
				<div class="subsection-header-div">
					<p class="subsection-header" id="huffman-coding-algorithm">Huffman Coding Algorithm</p>
					<p>
						To continue.
					</p>
				</div>
			</div> -->

			<div class="section-header-div">
				<p class="section-header" id="glossary">Glossary</p>
				<div class="subsection-header-div">
					<p class="subsection-header" id="cardinality">Cardinality</p>
					<p>
						The cardinality of a set represents the number of elements in the set.
					</p>
				</div>
			</div>

			<div class="subsection-header-div">
				<p class="subsection-header" id="uniquely-decodable">Uniquely Decodable</p>
				<p>
					Codes that are uniquely decodable, instantaneous codes, or prefix-free codes are called such because the
					decoder that scans the code instantly recognizes the end of the codeword.
				</p>
			</div>
		</div>
	</div>
	</div>

	<!--Collapsible table of contents-->
	<div class="table-of-contents-collapsible-div"></div>
	<!-- end of collapsible table of contents -->

	<!-- Footer bar -->
	<div class="footer-placeholder" id="footer-placeholder"></div>
	<!-- end of Footer bar -->

	<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"
		integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo"
		crossorigin="anonymous"></script>
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
	<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"
		integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM"
		crossorigin="anonymous"></script>
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
	<script src="/assets/js/preset-divs.js"></script>
	<script src="/assets/js/helper-functions.js"></script>
	<script src="/assets/js/script.js"></script>
</body>

</html>