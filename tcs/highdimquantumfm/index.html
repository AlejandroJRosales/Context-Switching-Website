<!DOCTYPE html>
<html>

<head>
	<!-- Style sheet for Bootstrap -->
	<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
		integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous" />

	<!-- Style sheets for "font awesome" icons -->
	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.13.0/css/all.css">
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

	<link rel="stylesheet" href="/assets/css/style.css">

	<meta name="viewport" content="width=device-width, initial-scale=1">

	<title>High-Dimensional Quantum Feture Mapping - Context Switching</title>
</head>

<body>
	<div class="nav-placeholder" id="nav-placeholder"></div>
	<div class="title-section"></div>

	<div class="information">

		<div class="table-of-contents"></div>

		<div class="category-header-div">
			<p class="category-header" id="high-dimensional-quantum-feture-mapping">High-Dimensional Quantum Feture
				Mapping</p>

			<div class="section-header-div">
				<p class="section-header" id="qpca">Quantum Principal Component Analysis</p>
				<p>
					Quantum Principal Component Analysis identifies large eigenvalues of unknown density matrices
					utilizing corresponding eigenvectors in \(O(\log d)\). Where principal component analysis analyzes
					positive semi-definite Hermitian matrices by decomposing eigenvectors in relation to the largest
					eigenvalues in the matrix for dimensionality reduction. Improved computational complexity will
					hopefully allow new methods for state discrimination and cluster assignment for variational and
					kernel classification machine learning algorithms.
				</p>

				<p>
					Consider a dataset \(\left\{\mathbf{x}_i\right\}_{i=1}^N\) with \(N\) data points where each data
					point is a \(D\)-dimensional column vector \(\mathbf{x}_i=\) \(\left(x_{i 1}, x_{i 2}, \cdots, x_{i
					D}\right)^T \in \mathbb{R}^D\). Through principal component analysis we can lower the dimensional
					space to a \(N\times D\) matrix \(X=\left(\mathbf{x}_1, \cdots, \mathbf{x}_N\right)^T\) while
					maximally preserving data variance. Where an eigendecomposition for a single matrix \(X\) is:
				</p>

				<p>
					\(X=\sum_{j=1}^D \sigma_j\left|\mathbf{u}_j\right\rangle\left\langle\mathbf{v}_j\right|\)
				</p>

				<p>
					such that \(\left\{\sigma_j \in \mathbb{R}_{\geq
					0}\right\}_{j=1}^D\) are the
					singular eigenvalues of the matrix in descending order and \(\left\{\left|\mathbf{u}_j\right\rangle
					\in \mathbb{R}^N\right\}_{j=1}^D\) and
					\(\left\{\left|\mathbf{v}_j\right\rangle \in \mathbb{R}^D\right\}_{j=1}^D\) are, respectively, the
					left and right singular eigenvectors or principal components.
				</p>

				<div class="subsection-header-div">
					<p class="subsection-header" id="procedure-quantum-data-compression">Quantum Data Compression
						Algorithm</p>
					<p>
						The quantum algorithm transforms the quantum state \(|\psi_{s}\rangle\) that holds the original
						data to another quantum state \(|\psi_{e}\rangle\) storing new low-dimensional data points in
						quantum parallel:
					</p>

					<p>
						\({\displaystyle |\psi_s\rangle:=\frac{\sum_{i=1}^{N}|i\rangle \otimes
						\mathbf{x}_{i}}{||X||_{F}} }\)
						\(\mapsto\)
						\({\displaystyle |\psi_{e}\rangle:=\frac{\sum_{i=1}^{N}|i\rangle \otimes
						\mathbf{y}_{i}}{\|Y\|_F} }\)
					</p>

					<p>
						such that, \(\|X\|_F\) and \(\|Y\|_F\) are the Frobenius norms of \(X\) and \(Y\). Let:
					</p>

					<p>
						\(\mathbf{x}_i=\sum_{j=1}^D x_{i j}|j\rangle=||\mathbf{x}_i||\;|\mathbf{x}_{i}\rangle\)
						<br>
						\(\mathbf{y}_i=\sum_{j=1}^d y_{i j}|j\rangle=||\mathbf{y}_i||\;|\mathbf{y}_i\rangle\)
					</p>

					<p>
						To begin, we will asssume the data set \(\{\mathbf{x}_i\}_{i=1}^N\), or matrix \(X\),
						is stored in a quantum random access memory qRAM, such that qRAM takes
						\(|i\rangle|0\rangle|0\rangle \rightarrow|i\rangle\left|a_i\right\rangle|| \vec{a}_i|\rangle\).
						Next, using the quantum access we now have to vectors and norms, we constuct the state
						\(\sum_i\left|\vec{a}_i\right|\left|e_i\right\rangle\left|a_i\right\rangle\), where the density
						matric for the first register is exactly \(X\). Now, we must create \(n=O\left(t^2
						\epsilon^{-1}\right)\) copies of \(X\), in order to have an accuracy \(\epsilon\) in time
						\(O(n\log d)\) by completing \(e^{-i X t}\) implementations of this process.
					</p>

					<p>
						An important aspect to keep in mind about this algorithm is that the density matrix
						exponentiation is most effective when some of the eigenvalues \(p\) are large. This is because
						we are utilizing quantum parallelism to amplify deviations in the probability amplitudes to
						reveal eigenvectors corresponding to the large eigenvalues of the unknown state. If all
						eigenvalues are of size \(O(1/d)\), the the time complexity increases to \(t=(d)\) to generate a
						transformation such that it rotates the input state \(\sigma\) to an orthogonal state.
					</p>

					<p>
						To continue.
					</p>
				</div>
			</div>

			<div class="section-header-div">
				<p class="section-header" id="efficent-discrete-feature-mapping">Efficient Discrete Feature Encoding</p>
				<p>
					To continue.
				</p>
			</div>
		</div>
	</div>

	<!--Collapsible table of contents-->
	<div class="table-of-contents-collapsible-div"></div>
	<!-- end of collapsible table of contents -->

	<!-- Footer bar -->
	<div class="footer-placeholder" id="footer-placeholder"></div>
	<!-- end of Footer bar -->

	<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"
		integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo"
		crossorigin="anonymous"></script>
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
	<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"
		integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM"
		crossorigin="anonymous"></script>
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
	<script src="/assets/js/preset-divs.js"></script>
	<script src="/assets/js/helper-functions.js"></script>
	<script src="/assets/js/script.js"></script>
</body>

</html>