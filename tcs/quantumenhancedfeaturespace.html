<!DOCTYPE html>
<html>

<head>
	<!-- Style sheet for Bootstrap -->
	<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
		integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous" />

	<!-- Style sheets for "font awesome" icons -->
	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.13.0/css/all.css">
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

	<link rel="stylesheet" href="/assets/css/style.css">

	<meta name="viewport" content="width=device-width, initial-scale=1">

	<title>Quantum Enhanced Feature Space - Context Switching</title>
</head>

<body>
	<div class="nav-placeholder" id="nav-placeholder"></div>
	<div class="title-section"></div>

	<div class="information">

		<div class="table-of-contents"></div>

		<div class="category-header-div">
			<p class="category-header" id="quantum-enhanced-feature-space">Quantum Enhanced Feature Space</p>

			<div class="section-header-div">
				<p class="section-header" id="quantum-support-vector-machine">Quantum Support Vector Machine</p>
				<p id="section-reference-1">
					Section Reference:
					<a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/pdf/1804.11326.pdf">
						<i>
							Supervised Learning with Quantum Enhanced Feature Spaces by: Vojtech Havlicek,âˆ— Antonio D. Corcoles,
							Kristan Temme, Aram W. Harrow, Abhinav Kandala, Jerry M. Chow, and Jay M. Gambetta. IBM T.J.
							Watson Research Center, Yorktown Heights, NY 10598, USA and Center for Theoretical Physics,
							Massachusetts Institute of Technology, USA (Dated: June 7, 2018)
						</i>
						\(^{[1]}\)
					</a>
				</p>

				<div class="subsection-header-div">
					<p class="subsection-header" id="quantum-feature-introduction">Introduction</p>
					<p>
						Using quantum computing, the authors suggest obtaining a quantum advantage for
						Support Vector Machine SVM processing. In order to do this, the authors suggest mapping the SVM feature
						space provided in the purely classical data to quantum state space.
					</p>

					<p>
						For the problem, we have data from a training set \(T\) and a
						test set \(S\), where \(T, S\) are a subset \(\Omega\subset\mathbb{R}^{d}\).
						For each training set, we assume the data is labled by a map \(m: T \cup S \rightarrow\left\{+1,
						-1\right\}\) which is not given to the algorithm. The algorithm is given the training data labels of the
						training data and is asked to infer an approximate mapping \(\tilde{m}\). The goal of the training
						algorithm
						is to infer an approximate map on test set \(\tilde{m}: S\rightarrow\{+1,-1\}\) such that it matches the
						true
						map \(m(\vec{s})=\tilde{m}(\vec{s})\) with high probability for some given test data \(\vec{s}\in S\).
					</p>
					<p>
						The authors map the data non-linearly to a high dimensional space, which is the feature
						space, and then seperate the labeled sample by constructing a hyperplane. By using the quantum state space
						as the feature space, the authors hope to obtain a quantum advantage. This quantum state space as feature
						space is constructed by mapping the data non-linearly to a quantum state \(\Phi:\vec{x}\in\Omega\rightarrow
						|\Phi(\vec{x})\rangle\langle\Phi(\vec{x})|\). Looking at the non-linear mapping, we can see that the domain
						of the mapping \(\Phi\) is the data
						\(\vec{x}\in\Omega\subset\mathbb{R}^{d}\) or \(\vec{x}\in
						T\cup S\).
						The codomain or image of \(\Phi\) is a quantum state \(|\Phi(\vec{x})\rangle\langle\Phi(\vec{x})|\).
						\(|\Phi(\vec{x})\rangle\) is a part of infinite complex vector space or Hilbert Space. Note, that since
						\(|\Phi(\vec{x})\rangle\) is a part of complex vector space there exists a complex conjugate
						\(\langle\Phi(\vec{x})|\) that is a dual correspondance. We will look more at how this quantum feature
						mapping is done in the next section.
					</p>
				</div>
				<div class="subsection-header-div">
					<p class="subsection-header" id="quantum-feature-mapping">Quantum Feature Mapping</p>


					<p>
						The authors suggest that in order to test an advantage over classical approaches, a map based on circuts
						that are clasically hard to simulate needs to be constructed. The authors propose a cicut that works well
						in
						their expirements and is not too deep to test.
					</p>

					<p>
						First, a feature map for \(n\)-qubits is generated using the following unitary function:
					</p>

					<p>
						\(\mathcal{U}_{\Phi(\vec{x})}=U_{\Phi{(\vec{x})}}H^{\otimes n}U_{\Phi{(\vec{x})}}H^{\otimes n}\)
					</p>

					<p>
						where \(H\) is a conventional Hadmard gate and \(U_{\Phi(\vec{x})}\) is defined as:
					</p>

					<p>
						\(U_{\Phi(\vec{x})}=\exp(i\sum_{S\subseteq[n]}\phi_{S}(\vec{x})\prod_{i\in S}Z_{i})\)
					</p>

					<p>
						and is a diagonal gate in the Pauli Z-basis. For a single qubit, the unitary function \(U_{\Phi(x)}\) acts
						as a phase-gate \(Z_{x}\) of angle \(x\in\Omega\).
					</p>

					<p>
						The authors provide a circut diagram that represents this unitary function for feature mapping
						\(n\)-qubits. This circut diagram is given as:
					</p>

					<img src="/assets/images/quantum-feature-space-circut.png" alt="Quantum Feature Space Circut" class="figure"
						style="width:40%;height:auto;padding:3%3%;">

					<p class="figure-source-txt" id="section-reference-2">
						Image Source:
						<a class="sliding-link" href="#section-reference-1">
							\(^{[1]}\)
						</a>
					</p>
				</div>
			</div>

			<div class="subsection-header-div">
				<p class="subsection-header" id="quantum-enhanced-feature-space-data-generation">Data Generation</p>
				<p>
					First, we will define the map used for the artifical data. The data is generated of dimension \(n=d=2\) for a
					\(2\)-qubit system with the mapping
					\(\phi_{\{i\}}(\vec{x})=x_{i}\) and \(\phi_{\{1,2\}}(\vec{x})=(\pi-x_{1})(\pi-x_{2})\).
				</p>
				<p>
					Next, we look at how the data is generated. For the data vector labels \(\vec{x}\in T\cup S \subset (0,
					2\pi]^{2}\) the authors mention generating it using the parity function \(\mathbf{f}=Z_{1}Z_{2}\) and random
					unitary
					\(V\in SU(4)\).
				</p>
				<p>
					Next, to label the data the authors describe the following mapping. Given \(\Delta=0.3\), if:
				</p>

				<p>
					\(\langle\Phi(\vec{x})|V^{\dagger}\mathbf{f}V|\Phi(\vec{x})\rangle\geq\Delta\)
				</p>

				<p>
					then \(m(\vec{x})=+1\). If:
				</p>

				<p>
					\(\langle\Phi(\vec{x})|V^{\dagger}\mathbf{f}V|\Phi(\vec{x})\rangle\leq-\Delta\)
				</p>

				<p>
					then \(m(\vec{x})=-1\).
				</p>
			</div>

			<div class="subsection-header-div">
				<p class="subsection-header" id="quantum-enhanced-feature-proposed-svm-classifiers">Proposed SVM
					Classifiers</p>
				<div class="subsubsection-header-div">
					<p class="subsubsection-header" id="quantum-enhanced-feature-quantum-variational-classification">Quantum
						Variational Classification</p>
					<div class="subsubsubsection-header-div">
						<p class="subsubsubsection-header" id="svm-classifier-type1-protocol">Protocol</p>

						<p>
							The authors describe the process for their first classification protocol in the following four steps: <a
								class="sliding-link" href="#qvc-step1">feature map circut</a>, <a class="sliding-link"
								href="#qvc-step2">short depth quantum circut</a>, <a class="sliding-link" href="#qvc-step3">binary
								measurement</a>, and then <a class="sliding-link" href="#qvc-step4">empirical distribution</a>.

						<p id="qvc-step1"><i>Feature Map Circut</i></p>
						<p>
							The data
							\(\vec{x}\in\Omega\) is mapped to a reference state \(|0\rangle^{n}\) using the feature map circut
							\(\mathcal{U}_{\Phi(\vec{x})}\).
						</p>

						<p id="qvc-step2"><i>Short Depth Quantum Circut</i></p>
						<p>
							A short depth quantum circut \(W(\vec{\theta})\) is applied to the feature state is a variational
							circut used for the optimization method. A depiction of this short depth quantum circut is given by the
							authors and shown in the figure below:
						</p>


						<img src="/assets/images/short-depth-quantum-circuit.png" alt="Short Depth Quantum Circut" class="figure"
							style="width:35%;height:auto;padding:1%1%;">

						<p class="figure-source-txt" id="section-reference-2">
							Image Source:
							<a class="sliding-link" href="#section-reference-1">
								\(^{[1]}\)
							</a>
						</p>

						<p>
							We will now define this short depth quantum circut \(W(\vec{\theta})\). The authors use an Ansatz for the
							variational
							unitary defined as:
						</p>

						<p>
							\(W(\vec{\theta})=U_{loc}^{(l)}(\theta_{l})U_{ent}...U_{loc}^{(1)}(\theta_{1})\)
						</p>

						<p>
							Where \(U_{ent}\) is an alternating layers of entangling gates and is defined as:
						</p>

						<p>
							\(U_{ent}=\prod_{(i,j)\in E}\mathbf{CZ}(i,j)\)
						</p>

						<p>
							Here, \(E\) is the an edge in the circut defined vetice set \(\{v_{i}, v_{j}\}\in V\). \(\mathbf{CZ}\)
							is
							a
							controlled phase gate applied along the
							edges \((i,j)\in E\) which the authors state is present in the connectivity of the superconducting chip.
							The \(\mathbf{CZ}\) circut looks like the following:
						</p>

						<img src="/assets/images/cz-gate.png" alt="CZ Circut" class="figure"
							style="width:20%;height:auto;padding:1%1%;">

						<p class="figure-source-txt" id="section-reference-2">
							Image Source:
							<a class="sliding-link" href="#section-reference-1">
								\(^{[1]}\)
							</a>
						</p>

						<p>
							\(U_{loc}^{(l)}(\theta_{l})\) is full layers single qubit rotations defined as:
						</p>

						<p>
							\(U_{loc}^{(t)}(\theta_{t})=\bigotimes_{i=1}^{n}U(\theta_{i,t})\)
						</p>

						<p>
							where \(U(\theta_{i,t})\in SU(2)\). This variational circut is parametrized by
							\(\vec{\theta
							}\in\mathbb{R}^{2n(l+1)}\) and it is waht is optimized during training as this is what classifies the
							data.
						</p>

						<p id="qvc-step3"><i>Binary Measurment</i></p>
						<p>
							Given that the problem is a two label classification \(y\in\{+1,-1\}\), the authors apply a binary
							measurment \(\{M_{y}\}\) to the state \(W(\vec{\theta})\mathcal{U}_{\Phi(\vec{x})}|0\rangle^{n}\).
						<p>
						<p>
							The authors describe the binary measurment in the following way. The measurment is in the \(Z\)-basis,
							outputs
							the bit-string
							\(z\in\{0,1\}^{n}\), where the bit-string is then passed to the boolean function
							\(f:\{0,1\}^{n}\rightarrow\{+1,-1\}\). The binary measurment is defined
							as \(M_{y}=2^{-1}(\mathbb{1}+y\mathbf{f})\), where \(\mathbf{f}=\sum_{z\in\{0,1\}^n}f(z)|z\rangle\langle
							z|\).
						</p>

						<p>
							From this third step, the probability for the outcome \(y\) is obtained. This probability
							\(p_{y}(\vec{x})\) is
							defined as:
						</p>

						<p>
							\(p_{y}(\vec{x})=\langle\Phi(\vec{x})|W^{\dagger}(\vec{\theta})M_{y}W(\vec{\theta})|\Phi(\vec{x})\rangle\)
						</p>

						<p id="qvc-step4"><i>Empirical Distribution</i></p>

						<p>
							For the final decision ruling of \(y\), \(R\) repeated measurment shots are preformed, yielding the
							empircal
							distribution \(\hat{p}(\vec{x})\), where if \(\hat{p}_{-y}(\vec{x}-yb)<\hat{p}_{y}(\vec{x})\) the label
								assigned is \(\tilde{m}(\vec{x})=y\). The authors introduced a bias parameter \(b\in[-1,1]\) that can
								also be optimized during training. </p>

								<p>
									The authors mention that the feature map circut \(\mathcal{U}_{\Phi(\vec{x})}\) and the boolean
									function
									\(f\) are fixed choices. The parameters that are being optimized during training are
									\((\vec{\theta},b)\)
									and
									in order to be optimized, a cost-function is need to be defined. To do so, we need to define an error
									probability first, which is what we will look at in the next section.
								</p>
					</div>

					<div class="subsubsubsection-header-div">
						<p class="subsubsubsection-header" id="svm-classifier-type1-error-probability">Error Probability</p>

						<p>
							In order to find the empirical risk \(R_{emp}(\vec{\theta})\) of the empirical distribution
							\(\hat{p}(\vec{x})\) we define the error probability of assigning the incorrect labels averaged over the
							samples in the training set \(T\). The authors define this error probability as:
						</p>

						<p>
							\(R_{emp}(\vec{\theta})=\frac{1}{|T|}\sum_{\vec{x}\in T}Pr(\tilde{m}(\vec{x})\neq m(\vec{x}))\)
						</p>
					</div>
				</div>
				<div class="subsubsection-header-div">
					<p class="subsubsection-header" id="quantum-enhanced-feature-quantum-kernel-estimiation">Quantum Kernel
						Estimation</p>
					<p>
						To continue.
					</p>
				</div>
			</div>
		</div>
	</div>

	<!--Collapsible table of contents-->
	<div class="table-of-contents-collapsible-div"></div>
	<!-- end of collapsible table of contents -->

	<!-- Footer bar -->
	<div class="footer-placeholder" id="footer-placeholder"></div>
	<!-- end of Footer bar -->

	<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"
		integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo"
		crossorigin="anonymous"></script>
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
	<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"
		integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM"
		crossorigin="anonymous"></script>
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
	<script src="/assets/js/preset-divs.js"></script>
	<script src="/assets/js/helper-functions.js"></script>
	<script src="/assets/js/script.js"></script>
</body>

</html>