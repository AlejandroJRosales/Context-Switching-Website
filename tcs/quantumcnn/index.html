<!DOCTYPE html>
<html>

<head>
	<!-- Style sheet for Bootstrap -->
	<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
		integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous" />

	<!-- Style sheets for "font awesome" icons -->
	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.13.0/css/all.css">
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

	<link rel="stylesheet" href="/assets/css/style.css">

	<meta name="viewport" content="width=device-width, initial-scale=1">

	<title>Quantum Convolutional Neural Network - Context Switching</title>
</head>

<body>
	<div class="nav-placeholder" id="nav-placeholder"></div>
	<div class="title-section"></div>

	<div class="information">

		<div class="table-of-contents"></div>

		<div class="category-header-div">
			<p class="category-header" id="quantum-cnn">Quantum Convolutional Neural Network</p>

			<p id="code-reference-1">
				My code for related quantum neural network: <a target="_blank" rel="noopener noreferrer"
					href="https://github.com/AlejandroJRosales/QuantumNeuralNetwork/blob/main/qnn.py">
					<i>
						QuantumNeuralNetwork
					</i>
				</a>
			</p>

			<div class="section-header-div">
				<p class="section-header" id="research-relation">Introduction</p>
				<p>
					A quantum convolutional neural network QCNN circuit combines two key techniques: <a
						class="sliding-link" href="#mera">multi-scale
						entanglement renormalization ansatz</a>
					MERA, which is a variational ansatz for many-body wavefunctions, and nested <a
						href="/tcs/quantumec/">quantum error correction</a>
					QEC, which detects and corrects local quantum errors without collapsing the wavefunction. We will
					explore these two components, MERA and QEC, in detail. Next, we will look at the processes that make
					up these techniques, such as <a class="sliding-link" href="#forward-pass">quantum
						forward propagation</a> and <a class="sliding-link" href="#backward-pass">quantum back
						propagation</a>. However, before diving into these, we need to understand the underlying
					fundemental principles of quantum mechanics, mathematics, and computer science that form the
					foundation of a QCNN. Let's begin!
				</p>

				<!-- <p>
					We will look at how <a href="/tcs/quantumcomputingtheory/">quantum computing</a> can be applied to
					classical deep learning like convolutional neural networks CNN, aptly called quantum convolutional
					neural network. These quantum-enhanced algorithms could pave the way for groundbreaking
					advancements in algorithms such as computer vision. It is known that quantum computing can improve
					the <a href="/tcs/algorithmicanalysis/">algorithmic complexity</a> of performing larger operations
					by exploiting <a href="/phys/quantummechanics/">quantum mechanics</a>. However, here we will look at
					how quantum computers can enhance the
					algorithmic complexity of classical machine learning algorithms. Utilizing quantum mechanical
					phenomena in classical machine learning algorithms like for CNN's can allow for an increased number
					or
					size of convolution kernels, and exploring larger or more complex input structures.
				</p> -->
			</div>
			<div class="section-header-div">
				<p class="section-header" id="tensor-network">Tensor Network</p>

				<p>
					We will start with tensor networks. Tensor networks are used in quantum mechanics to represent
					complex quantum states, particularly in many-body systems, by breaking them down into simpler,
					interconnected components. They help efficiently handle high-dimensional data that arises in quantum
					systems, such as entangled states, by using tensors (multi-dimensional arrays) to encode the
					relationships between different parts of the system. In these networks, each tensor represents a
					local degree of freedom, and the network structure encodes the global state of the system. They are
					defined by a set of tensors connected through shared indices, which represent interactions between
					different parts of the system. Tensor networks are crucial for simulating quantum systems on
					classical computers, as they allow for efficient approximation of quantum states without needing to
					directly manipulate large Hilbert spaces.
				</p>

				<div class="subsection-header-div">
					<p class="subsection-header" id="mps">Matrix Product State</p>

					<p>
						Before analyzing MERA, let us familiarize ourselves with a less intricate tensor network, Matrix
						Product States MPS, to understand the underlying key concepts of tensor networks used for
						quantum many-body problems.
					</p>

					<p>
						A MPS can
						be considered as an one-dimensional lattice \(\mathcal{L}\) such that each site
						\(s\) hosts a spin
						for each state of the site
						\(|\Psi\rangle \in H_{\mathcal{L}}=\otimes_{\mathrm{s} \in \mathcal{L}} H_s\) where \(H\)
						denotes
						complex vector space, Hilbert Space. The complexity of the state grows exponentially with
						respect to the number of spins
						\(N\). The \(H\) space dimension is \(\operatorname{dim} H_\mathcal{L}=2^N\).
					</p>

					<p>
						We then need to reduce the degrees of freedom by identifying those that contain the most
						relevant information. We perform iterative reshaping of coefficient arrays and singular value
						decomposition SVD. SVD can correspond to the Schmidt decomposition for a properly reshaped array
						of state coefficients:
					</p>

					<p class="math-def">
						\(|\psi\rangle\) \(=\sum_{s_1, \ldots, s_N} c^{s_1, \ldots, s_N}\left|s_1, \ldots,
						s_N\right\rangle\)
					</p>

					<p>
						depending on the chosen bipartition of the lattice. The chosen bipartition is uniquely
						determined
						in the one dimension case with:
					</p>

					<p class="math-def">
						\(c^{s_1, \ldots, s_N} \rightarrow c^{\left(s_1, \ldots, s_\ell\right)},\) \(\left(s_{\ell+1},
						\ldots,
						s_N\right)\) \(=\sum_{a_\ell} U_{a_\ell}^{\left(s_1, \ldots, s_\ell\right)} \Lambda^{a_\ell,
						a_\ell}\left(V^{\dagger}\right)_{a_\ell}^{\left(s_{\ell+1}, \ldots, s_N\right)}\)
					</p>

					<p>
						where \(\Lambda\) is a diagonal matrix containing Schmidt coefficients \(\lambda_{a_{l}}\) and
						physical indices (\(\ldots\)) refer to matrix unfolding for tensors.
					</p>

					<p>
						For a properly reshaped array of state
						coefficients for some state \(|\Psi\rangle\), given the following decomposition for rank-3
						tensors \(A_{a_\ell}^{1,\left(s_1,
						\ldots, s_\ell\right)}\) \(=U_{a_l}^{\left(s_1, \ldots, s_\ell\right)}\) and
						\(B_{a_l}^{\left(s_{\ell+1},
						\ldots, s_N\right), 1}\) \(=\left(V^{\dagger}\right)_{a_l}^{\left(s_{\ell + 1} \ldots,
						s_N\right)}\) we
						get:
					</p>

					<p class="math-def">
						\(|\psi\rangle\) \(=\sum_{s_1, \ldots, s_N} \sum_{a_{\ell}} A_{a_{\ell}}^{1,\left(s_1, \ldots,
						s_{\ell}\right)} \Lambda^{a_\ell, a_\ell}\) \(B_{a_{\ell}}^{\left(s_{\ell+1}, \ldots,
						s_N\right),
						1}\left|s_1, \ldots, s_N\right\rangle\) \(=\sum_{a_{\ell}}
						\lambda_{a_{\ell}}|a\rangle_{a_{\ell}}|b\rangle_{a_l}\)
					</p>

					<p>
						which we can see illustrated in the figure below:
					</p>

					<img src="/assets/images/1-dim-mps-schematic.png"
						alt="Schematic representation of 1-dimmensional matrix product state schematic with rank-3 tensors."
						class="figure-ignore" style="width:45%;height:auto;padding:0%0%;">

					<p class="figure-source-txt">
						Image Source: <a target="_blank" rel="noopener noreferrer"
							href="https://www.mdpi.com/2673-8716/3/3/33">https://www.mdpi.com/2673-8716/3/3/33</a>
					</p>

					<p>
						To continue.
					</p>
				</div>
				<div class="subsection-header-div">
					<p class="subsection-header" id="mera">Multi-scale Entanglement
						Renormalization Ansatz</p>
					<p>
						Entanglement renormalization is a numerical technique that locally reorganizes the Hilbert space
						of a quantum
						many-body system to reduce entanglement in its wave function. It addresses computational
						challenges of real-space renormalization group RG methods, which struggle with
						the rapid growth of degrees of freedom that occur during successive transformations of RG
						transformations.
					</p>

					<p>
						The key idea is that as a result of local character of physical interactions, some relevant
						degrees of freedom in the
						system's ground state of many-body system can be decoupled from the rest by applying unitary
						transformations called disentanglers to small regions, isolating and removing these degrees of
						freedom from the system, preventing their accumulation in future descriptions.
					</p>

					<p>
						This approach enables more efficient real-space RG transformations, capable of handling large 1D
						and 2D lattice systems, even at quantum critical points. It also forms the basis for the MERA,
						a variational method for approximating many-body states. MERA is based on a class of quantum
						circuts and succesful at describing ground state at quantum criticality or topological order. A
						key property of MERA that we will focus on for QCNN is how, from a computiational perspective,
						MERA efficently optimizes its tensors based on the evalution of expected values of local
						observables.
					</p>

					<p>
						Let \(\mathcal{L}\) denote a \(D\)-dimensional lattice with \(N\) sites. Each site
						\(s_{1},...,s_{N} \in \mathcal{L}\) is a described by a Hilbert space \(\mathbb{V}\) of finite
						dimension \(d\), such that \(\mathrm{V}_{\mathcal{f}} \cong \mathrm{V}^{\otimes N}\). MERA is an
						ansatz used to describe certai pure states \(|\Psi\rangle \in \mathbb{V}_{\mathcal{L}}\) of
						lattice \(\mathcal{L}\), or of subspaces \(\mathbb{V}_U \subseteq \mathbb{V}_{\mathcal{L}}\).
					</p>

					<p>
						The MERA can be viewed in two ways: as a quantum circuit \(\mathcal{C}\), where the output wires
						correspond to the lattice sites \(\mathcal{L}\), or as a coarse-graining process that maps
						\(\mathcal{L}\) to
						increasingly coarser lattices, implementing a renormalization-group transformation. We'll
						briefly explore these interpretations, compare MERA schemes, and discuss how to use space
						symmetries.
					</p>

					<p>
						To continue.
					</p>
				</div>
			</div>

			<div class="section-header-div">
				<p class="section-header" id="qcnn-circut">Quantum Convolutional Neural Network Circut</p>
				<p id="section-reference-1">
					Section Reference:
					<a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/pdf/quant-ph/0610099">
						<i>
							Vidal, G. (2006, October 12). A class of quantum many-body states that can be
							efficiently
							simulated. arXiv. https://arxiv.org/abs/quant-ph/0610099
						</i>
						\(^{[1]}\)
					</a>
				</p>

				<p>
					Consider a square lattice \(\mathcal{L}\) in \(D\) spatial dimensions with \(N\) sites, where
					each
					site \(s_{1},...,s_{N} \in \mathcal{L}\) is a complex vector space \(\mathbb{V}\) with finite
					dimension
					\(\chi\),
					termed the bond dimension. Site \(s\) can be described by a pure quantum state
					\(|\Psi\rangle
					\in \mathbb{V}^{\otimes N}=\mathbb{V}_\mathcal{L}\). This state is made of \(N\) quantum wires,
					which has a reduced density matrix
					\(\rho^{[s]}=\operatorname{tr}_{\bar{s}}(|\Psi\rangle\langle\Psi|)\). Unitary gates \(u\) transform
					the unentangled state state \(|0\rangle^{\otimes N}\) into state \(|\Psi\rangle\), which is
					be
					generated by a quantum circut \(\mathcal{C}\) with depth \(\Theta \equiv 2 \log _2(N)-1\). A
					figure
					of this quantum circut is given below:
				</p>

				<img src="/assets/images/mera-as-quantum-circut-c.png"
					alt="Schematic representation of quantum circut with 2N-1 gates that transformes initial state to N-site state of 1D lattice."
					class="figure-ignore" style="width:45%;height:auto;padding:0%0%;">

				<p class="figure-source-txt">
					Image Source: <a class="sliding-link" href="#section-reference-1">\([1]\)</a>
				</p>

				<p>
					Generically, each unitary gate \(u\) in the circuit \(\mathcal{C}\) incoporates some small number
					\(p\) of wires.
				</p>

				<p>
					To continue.
				</p>
			</div>

			<div class="section-header-div">
				<p class="section-header" id="forward-pass">Quantum Forward Propagation</p>
				<p id="section-reference-2">
					Section Reference:
					<a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/pdf/1911.01117.pdf">
						<i>
							Kerenidis, I., Landman, J., & Prakash, A. (2019, November 4). Quantum algorithms for deep
							convolutional neural networks. arXiv. https://arxiv.org/abs/1911.01117
						</i>
						\(^{[2]}\)
					</a>
				</p>

				<p>
					To continue, we will define the subprocedures of a QCNN. To do so, we reference a different paper
					than the one above. The authors describe the procedure for <a class="sliding-link"
						href="#quantum-convolution">quantum
						convolution</a> in the following four
					sequential steps: <a class="sliding-link" href="#quantum-inner-product-estimation">inner
						product estimation</a>, <a class="sliding-link" href="#qc-non-linearity">non
						linearity</a>, <a class="sliding-link" href="#quantum-sampling">quantum sampling</a>, and then
					<a class="sliding-link" href="#qram-update-pooling">quantum random access memory update and
						pooling</a>. We will look at each of these steps in depth in the next section, however,
					we will first define key variables and concepts used throughout the described procedure.
				</p>

				<p>
					The input for the quantum convolution layer is a \(3\)D tensor input \(X^{\ell} \in
					\mathbb{R}^{H^{\ell} \times W^{\ell} \times D^{\ell}}\) and the weights layer, filter layer, or
					kernel layer is a \(4\)D tensor \(K^{\ell} \in \mathbb{R}^{H \times W \times D^{\ell}
					\times D^{\ell+1}}\), where the input and kernel layer are both stored in QRAM. Given precision
					parameters \(\epsilon\),
					\(\Delta>0\), there exists a quantum algorithm that computes a quantum state that is \(\Delta\)
					close to \(|f(\bar{X}^{\ell+1})\rangle\) where \(X^{\ell+1}=X^{\ell} * K^{\ell}\), and \(f:
					\mathbb{R} \mapsto[0, C]\) is a non-linear activation function. Note, this function could be a
					sigmoidal, hyperbolic tangent, ReLU, softmax, or any other activation function and is rather
					dependent mainly
					on the task the activation function needs to complete. To continue, a classical appoximation for
					the computer quantum state exists where:
				</p>

				<p class="math-def">
					\(\left\|f\big(\bar{X}^{\ell+1}\big)-f\big(X^{\ell+1}\big)\right\|_{\infty} \leq
					\epsilon\)
				</p>

				<!-- <p>
						The time complexity of the quantum algorithm that computes the output quantum state
						\(|f(\bar{X}^{\ell+1})\rangle\)
						is \(\widetilde{O}(M / \epsilon)\). In this equation, \(M\) denotes the maximum norm of
						the product state between one of the kernels and one of the tensor input regions in
						\(X^{\ell}\), where the size is \(HW D^{\ell}\). It is important to note, that
						\(\widetilde{O}\) is made to hide factors poly-logarithmic in \(\Delta\) with respect to the
						size of \(X^{\ell}\) and \(K^{\ell}\).
					</p> -->

				<p>
					Given that a convolution product is equivalant to a matrix-matrix multiplication and the
					convolutional product between \(X^{\ell}\) and \(K^{\ell}\) is:
				</p>

				<p class="math-def">
					\(X_{i^{\ell+1}, j^{\ell+1}, d^{\ell+1}}^{\ell+1}=\) \(\sum_{i=0}^H \sum_{j=0}^W
					\sum_{d=0}^{D^{\ell}} K_{i, j, d, d^{\ell+1}}^{\ell} X_{i^{\ell+1}+i, j^{\ell+1}+j, d}^{\ell}\)
				</p>

				<p>
					it is possible to reformulate this convolution product equation as a matrix product. A diagram
					of this reshaping of the input and kernel is given by the authors and depicited below:
				</p>

				<img src="/assets/images/quantum-convolution-matrix-diagram.png"
					alt="Quantum Convolution Matrix Reshaping" class="figure-ignore"
					style="width:45%;height:auto;padding:0%0%;">

				<p class="figure-source-txt" id="section-reference-2">
					Image Source:
					<a class="sliding-link" href="#section-reference-2">
						\([2]\)
					</a>
				</p>

				<p> To express this reformulation mathematically, we must do the following. First, the original
					\(3\)D tensor input for the quantum convolution layer \(X^{\ell} \in
					\mathbb{R}^{H^{\ell} \times W^{\ell} \times D^{\ell}}\) and the \(4\)D tensor kernel layer
					\(K^{\ell} \in \mathbb{R}^{H \times W \times D^{\ell}
					\times D^{\ell+1}}\) needs to be reshaped to matrices. First, \(X^{\ell}\) needs to be expanded
					into a matrix \(A^{\ell} \in\) \(\mathbb{R}^{\left(H^{\ell+1} W^{\ell+1}\right) \times\left(H W
					D^{\ell}\right)}\), such that each row of \(A^{\ell}\) is a vectorized version of a subregion of
					\(X^{\ell}\). Next, the original kernel tensor \(K^{\ell}\) is reshaped into a matrix \(F^{\ell}
					\in\) \(\mathbb{R}^{\left(H W D^{\ell}\right) \times D^{\ell+1}}\), such that each column of
					\(F^{\ell}\) is a vectrozied version of one of the \(D^{\ell+1}\) kernels.
				</p>

				<p>
					This matrix expression of the tensor input and kernel is needed for the
					convolution product \(X^{\ell} * K^{\ell}=X^{\ell+1}\) to be written as a matrix multiplication,
					such that each column of the output matrix \(Y^{\ell+1} \in
					\mathbb{R}^{\left(H^{\ell+1} W^{\ell+1}\right) \times D^{\ell+1}}\) is a first vectorized form
					of one of the \(D^{\ell+1}\) channels of \(X^{\ell+1}\). Later, we will dicuss how quantum
					computing, specifically quantum parallelism can not only be applied, but improve the time
					complexity of this step.
				</p>

				<p>
					Lastly, quantum states proportional to the rows of input \(A^{\ell}\) and \(F^{\ell}\) are
					used,
					denoted \(|A_p^{\ell}\rangle\) and \(|F_q^{\ell}\rangle\) respectively. These quantum states
					are
					defined as:
				</p>

				<p class="math-def">
					\( \left|A_p^{\ell}\right\rangle=\) \(\frac{1}{\left\|A_p^{\ell}\right\|} \sum_{r=0}^{H W
					D^{\ell}-1} A_{p r}^{\ell}|r\rangle\)
				</p>

				<p class="math-def">
					\(\left|F_q^{\ell}\right\rangle=\) \(\frac{1}{\left\|F_q^{\ell}\right\|}
					\sum_{s=0}^{D^{\ell+1}-1}
					F_{s q}^{\ell}|s\rangle\)
				</p>

				<p>
					and will continue to be used throughout this section.
				</p>

				<div class="subsection-header-div">
					<p class="subsection-header" id="quantum-convolution">Quantum Convolution</p>


					<div class="subsubsection-header-div">
						<p class="subsubsection-header" id="quantum-inner-product-estimation">Inner Product
							Estimation</p>
						<p>
							First we load input row vector \(A_p^{\ell}\) and kernel vector \(F_q^{\ell}\) into
							quantum
							states by quering QRAM in the following manner:
						</p>

						<p class="math-def">
							\(\left\{\begin{aligned}
							|p\rangle|0\rangle & \mapsto|p\rangle\left|A_p^{\ell}\right\rangle \\
							|q\rangle|0\rangle & \mapsto|q\rangle\left|F_q^{\ell}\right\rangle
							\end{aligned}\right.\)
						</p>

						<p>
							This is done so that following mapping can be perfromed with the two vectors:
						</p>

						<p class="math-def">
							\(\frac{1}{K} \sum_{p, q}|p\rangle|q\rangle \mapsto \) \(\frac{1}{K} \sum_{p,
							q}|p\rangle|q\rangle|\bar{P}_{p q}\rangle\left|g_{p q}\right\rangle\)
						</p>

						<p>
							Here \(\bar{P}_{p q}\) is the inner product estimation of
							\(A_p^{\ell}\) and \(F_q^{\ell}\) such that:
						</p>

						<p class="math-def">
							\(\left\|\bar{P}_{p q}-\frac{1+\left\langle A_p^{\ell} \mid
							F_q^{\ell}\right\rangle}{2}\right\|_{\infty} \leq \epsilon\)
						</p>

						<p> where the "true" value of the inner product is
							calculated as \(P_{p q}=\frac{1+\left\langle A_p^{\ell} \mid
							F_q^{\ell}\right\rangle}{2}\),
							and \(\epsilon\) is some chosen constant. The
							normalization factor is \(K=\sqrt{H^{\ell+1} W^{\ell+1} D^{\ell+1}}\) and
							\(|g_{pq}\rangle\) is some garbage state.
						</p>
					</div>

					<div class="subsubsection-header-div">
						<p class="subsubsection-header" id="qc-non-linearity">Non Linearity</p>

						<p>
							Our obtained approximated convolution output \(\bar{P}_{p q}\) or
							\(\bar{Y}^{\ell+1}\) differs from the "true" convolution output \(Y_{p,
							q}^{\ell+1}=\left(A_p^{\ell}, F_q^{\ell}\right)\) by \(\epsilon\). Now, we apply a
							non-linear
							function \(f\) as a boolean circut giving the quantum state:
						</p>

						<p class="math-def">
							\(\frac{1}{K} \sum_{p, q}|p\rangle|q\rangle|f(\bar{Y}_{p,q}^{\ell+1})\rangle\left|g_{p
							q}\right\rangle\)
						</p>
					</div>
				</div>

				<div class="subsection-header-div">
					<p class="subsection-header" id="quantum-sampling">Quantum Sampling</p>
					<p>
						To procure the state below, states are conditionally rotated and the probabilistic
						amplitudes
						are
						amplified, such that we arrive at the state:
					</p>

					<p class="math-def">
						\(\frac{1}{K} \sum_{p, q} \alpha_{p
						q}^{\prime}|p\rangle|q\rangle|f(\bar{Y}_{p,q}^{\ell+1})\rangle\left|g_{p q}\right\rangle\)
					</p>

					<p>
						We will now look at two steps in depth that comprise quantum sampling: <a class="sliding-link"
							href="#conditional-rotation">conditional rotation</a> and <a class="sliding-link"
							href="#amplitude-amplification">amplitude amplification</a>.
					</p>
					<div class="subsubsection-header-div">
						<p class="subsubsection-header" id="conditional-rotation">Conditional Rotation</p>
						<p>
							The conditional rotation step aims to update the probability amplitudes, such that the
							highest values in \(|f(\bar{Y}^{\ell+1})\rangle\) have the highest probabilities when
							the state
							is measured. Applying conditional rotation on an ancillary qubit proportional to the
							convolution output \(f(\bar{Y}_{p, q}^{\ell+1})\) is a way to do so. The following
							rotation applied on an ancillary qubit looks like the following:
						</p>

						<p class="math-def">
							\(|f(\bar{Y}_{p, q}^{\ell+1})\rangle|0\rangle\mapsto\) \(|f(\bar{Y}_{p,
							q}^{\ell+1})\rangle\bigg(\sqrt{\frac{f(\bar{Y}_{p, q}^{\ell+1})}{\max_{p,q}
							f(\bar{Y}_{p, q}^{\ell+1})}}|0\rangle\) \(+\sqrt{1-\left(\frac{f(\bar{Y}_{p,
							q}^{\ell+1})}{\max_{p,q}
							f(\bar{Y}_{p, q}^{\ell+1})}\right)^2}|1\rangle\bigg)\)
						</p>

						<p>
							To simplify the notation, so we can perhpas more clearly see what is going on, we will
							let \(x=f(\bar{Y}_{p q}^{\ell+1})\) and \(\beta=\sqrt{1-\big(\frac{x}{\max
							x}\big)^2}\), where \(\max x=\max _{p, q} f(\bar{Y}_{p q}^{\ell+1})\). Now, we can
							rewrite the above as:
						</p>

						<p class="math-def">
							\(|x\rangle|0\rangle \mapsto|x\rangle\left(\sqrt{\frac{x}{\max
							x}}|0\rangle+\beta|1\rangle\right)\)
						</p>

						<p>
							To write the output of the conditional rotation in terms of quantum superposition for a
							quantum, if we let \(\alpha_{p q}=\sqrt{\frac{f(\bar{Y}_{p q}^{\ell+1})}{\max _{p,
							q}(f(\bar{Y}_{p q}^{\ell+1}))}}\), then we get:
						</p>

						<p class="math-def">
							\(\frac{1}{\sqrt{H W D}} \sum_{p, q}|p\rangle|q\rangle|f(\bar{Y}_{p
							q}^{\ell+1})\rangle\) \(\left(\alpha_{p q}|0\rangle+\sqrt{1-\alpha_{p
							q}^2}|1\rangle\right)\)
						</p>
					</div>
					<div class="subsubsection-header-div">
						<p class="subsubsection-header" id="amplitude-amplification">Amplitude Amplification</p>
						<p>
							To continue.
						</p>
					</div>
					<div class="subsubsection-header-div">
						<p class="subsubsection-header" id="quantum-tomography">Quantum Tomography</p>
						<p>
							To continue.
						</p>
					</div>
					<p>
						Quantum tomography is performed with precision \(\eta\) so that all values and positions
						\((p,
						q, f(\bar{Y}_{p q}^{\ell+1}))\) are obtained with a high probability. Values above \(\eta\)
						are
						known exactly, while values that are less than or equal to \(\eta\) are set to \(0\).
					</p>
				</div>

				<div class="subsection-header-div">
					<p class="subsection-header" id="qram-update-pooling">QRAM Update and Pooling</p>
					<p>
						Next, QRAM needs to updated with the value for the next layer, which is \(A^{\ell+1}\),
						while sampling. Pooling needs to be implemented in this step as well, either through a
						specific update or by using a QRAM data data structure. We will review <a class="sliding-link"
							href="#quantum-pooling">quantum pooling</a> more in depth later.
					</p>
					<div class="subsubection-header-div">
						<p class="subsubsection-header" id="quantum-pooling">Quantum Pooling</p>

						<p>
							At the end of layer \(\ell\), the pooling operation of size \(P\) is performed on the
							convolution layer output \(f(X^{\ell+1})\), yielding the tensor after pooling
							\(\tilde{X}^{\ell+1}\). Below, thee authors provide a figure shows a \(2\times 2\)
							tensor
							pooling such that different pooling regions having seperate colors:
						</p>

						<img src="/assets/images/qcnn-pooling.png" alt="QCNN Pooling Representation"
							class="figure-ignore" style="width:42.5%;height:auto;padding:0%0%;">

						<p class="figure-source-txt" id="section-reference-2">
							Image Source:
							<a class="sliding-link" href="#section-reference-2">
								\([2]\)
							</a>
						</p>

						<p>
							Here, for some point at position \((i^{\ell+1}, j^{\ell+1}, d^{\ell+1})\) in
							\(f(X^{\ell+1})\), the pooling region it corresponds to is at postion
							\((\tilde{i}^{\ell+1}, \tilde{j}^{\ell+1}, \tilde{d}^{\ell+1})\) in
							\(\tilde{X}^{\ell+1}\), such that:
						</p>

						<p class="math-def">
							\(\left\{\begin{array}{l}
							\tilde{d}^{\ell+1}=d^{\ell+1} \\
							\tilde{j}^{\ell+1}=\left\lfloor\frac{j^{\ell+1}}{P}\right\rfloor \\
							\tilde{i}^{\ell+1}=\left\lfloor\frac{i^{\ell+1}}{P}\right\rfloor
							\end{array}\right.\)
						</p>

						<p>
							This pooling operation occurs at the end of the layer during the <a class="sliding-link"
								href="#qram-update-pooling">QRAM update and pooling</a> operation, such that the
							sampled
							values are stored according to the pooling layers. Note, the authors state this kind of
							pooling
							can be efficiently applied to their QCNN structure, which we will look at to continue.
						</p>

						<p>
							Let's start by denoting output of layer \(\ell\) after quantum tomography
							\(\mathcal{X}^{\ell+1}\). Next, quantum pooling is applied to the yielding
							\(\tilde{\mathcal{X}}^{\ell+1}\), which has dimensions \(\frac{H^{\ell+1}}{P} \times
							\frac{W^{\ell+1}}{P} \times D^{\ell+1}\). \(\tilde{\mathcal{X}}^{\ell+1}\) will be used
							as the
							input for layer \(\ell + 1\) and the values for \(\tilde{\mathcal{X}}^{\ell+1}\) are
							stored in
							QRAM. The valyes are use to create trees \(\tilde{T}_{p^{\prime}}^{\ell+1}\), such that
							they
							relate to the matrix expansion \(\tilde{A}^{\ell+1}\) and that we will talk about later.
							It is
							important to note that \(\mathcal{X}^{\ell+1}\) cannot be know before quantum tomography
							is
							over. Thus, QRAM updating must be changed to pool in an online fashion each time a
							sample from
							\(|f(\bar{X}^{\ell+1})\rangle\) is drawn.
						</p>

						<p>
							To continue.
						</p>
					</div>
				</div>


				<div class="subsection-header-div">
					<p class="subsection-header" id="forward-pass-time-complexity">Quantum Forward Propagation Time
						Complexity</p>
					<p>
						The quantum time complexity of one forward pass through the convolution layer \(\ell\), where
						\(\widetilde{O}\) hides the polylogarithmic factors, is:
					</p>

					<p class="math-def">
						\(\widetilde{O}\left(\frac{1}{\epsilon \eta^2} \cdot \frac{M
						\sqrt{C}}{\sqrt{\mathbb{E}\left(f\left(\bar{X}^{\ell+1}\right)\right)}}\right)\)
					</p>

					<p>
						which can be written also as:
					</p>

					<p class="math-def">
						\(\widetilde{O}\left(\sigma H^{\ell+1} W^{\ell+1} D^{\ell+1} \cdot \frac{M \sqrt{C}}{\epsilon
						\sqrt{\mathbb{E}(f(\bar{X}^{\ell+1}))}}\right)\)
					</p>

					<p>
						Here, \(\sigma\in[0,1]\) is the fraction of sampled elements, where the number of elements is
						size \(H^{\ell+1} W^{\ell+1} D^{\ell+1}\). Note, that the the running time of the classical CNN
						layer is:
					</p>

					<p class="math-def">
						\(\widetilde{O}\left(H^{\ell+1} W^{\ell+1} D^{\ell+1} \cdot H W D^{\ell}\right)\)
					</p>

					<p>
						To continue.
					</p>
				</div>
			</div>

			<div class="section-header-div">
				<p class="section-header" id="backward-pass">Quantum Back Propagation</p>

				<p id="section-reference-2">
					Section Reference:
					<a class="sliding-link" href="#section-reference-2">
						\([2]\)
					</a>
				</p>

				<p>
					After the <a class="sliding-link" href="#forward-pass">quantum forward propagation</a> algorithm,
					the input matrix
					\(A^{\ell}\) and kernel matrix \(F^{\ell}\) for every layer
					\(\ell\) is stored in QRAM and the loss function \(\mathcal{L}\) is
					calculated. Next, the quantum back
					propagation algorithm will estimate the gradient tensor \(\frac{\partial \mathcal{L}}{\partial
					F^{\ell}}\) with some precision \(\delta > 0\) and update each element to perform gradient descent
					such that:
				</p>

				<p class="math-def">
					\(\displaystyle{ \forall(s, q),\left|\frac{\partial \mathcal{L}}{\partial F_{s,
					q}^{\ell}}-\overline{\frac{\partial \mathcal{L}}{\partial F_{s, q}^{\ell}}}\right|}\)
					\(\displaystyle{ \leq 2 \delta\left\|\frac{\partial \mathcal{L}}{\partial F^{\ell}}\right\|_2 }\)
				</p>

				<p>
					To continue.
				</p>
			</div>
		</div>
	</div>

	<div class="related-articles">
		<div class="section-header-div">
			<!-- Can make clickable image dynamically -->
			<p class="section-header" id="related-articles">Related Articles</p>

			<!-- Go back and add style to style sheet not here -->
			<div class="row row-cols-1 row-cols-md-3 g-4">
				<div class="col related-article-card">
					<div class="card h-100">
						<a href="/tcs/quantumsvm/">
							<img src="/assets/images/short-depth-quantum-circuit.png" class="card-img-top"
								alt="Nonlinear SVM Example" />
						</a>
						<div class="card-body">
							<h5 class="card-title">Quantum Support Vector Machine</h5>
							<p class="card-text">
								Using quantum computing, the authors exploit quantum mechanics for the algorithmic
								complexity optimization of a
								Support Vector Machine with high-dimensional feature space. Where the high-dimensional
								classical data is mapped
								non-linearly to Hilbert Space and a hyperplane in quantum space is used to separate and
								label the data. By using
								the...
							</p>
						</div>
						<div class="card-footer">
							<a href="/tcs/quantumsvm">Read More</a>
						</div>
					</div>
				</div>
				<div class="col related-article-card">
					<div class="card h-100">
						<!-- https://commons.wikimedia.org/wiki/File:Universal_line_bundle.jpg-->
						<a href="/tcs/quantumcomputingtheory/">
							<img src="/assets/images/bloch-sphere.png" class="card-img-top"
								alt="IBM Quantum Computer" />
						</a>
						<div class="card-body">
							<h5 class="card-title">Quantum Computing Theory</h5>
							<p class="card-text">
								Quantum Computing Theory is a field of computer science that uses the principles of
								quantum
								mechanics, mathematics, and computer science. By borrowing concepts from each field
								scientists can rigorously
								define both a broad and narrow theoretical model of a quantum computer and later apply
								it to the real world. These...
							</p>
						</div>
						<div class="card-footer">
							<a href="/tcs/quantumcomputingtheory/">Read More</a>
						</div>
					</div>
				</div>
				<div class="col related-article-card">
					<div class="card h-100">
						<!-- https://commons.wikimedia.org/wiki/File:HypercubeBiparti.pngg -->
						<a href="/math/informationtheory/">
							<img src="https://upload.wikimedia.org/wikipedia/commons/4/49/HypercubeBiparti.png"
								class="card-img-top" alt="Hypercube" />
						</a>
						<div class="card-body">
							<h5 class="card-title">Information Theory
							</h5>
							<p class="card-text">
								Three properties were required by Shannon: \(I(p) \geq 0\), i.e. information is a real
								non-negative measure. \(I(p_{1},p_{2})=I(p_{1})+I(p_{2})\) for independent events.
								\(I(p)\) is a continous
								function of \(p\). The mathematical function that satisfies these requirements is:
								\(I(p)=k\;log(p)\) In the
								equation, the value of \(k\) is arbitrary...
							</p>
						</div>
						<div class="card-footer">
							<a href="/math/informationtheory/">Read More</a>
						</div>
					</div>
				</div>
			</div>
		</div>
	</div>

	<!--Collapsible table of contents-->
	<div class="table-of-contents-collapsible-div"></div>
	<!-- end of collapsible table of contents -->

	<!-- Footer bar -->
	<div class="footer-placeholder" id="footer-placeholder"></div>
	<!-- end of Footer bar -->

	<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"
		integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo"
		crossorigin="anonymous"></script>
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
	<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"
		integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM"
		crossorigin="anonymous"></script>
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
	<script src="/assets/js/preset-divs.js"></script>
	<script src="/assets/js/helper-functions.js"></script>
	<script src="/assets/js/script.js"></script>
</body>

</html>